{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLPeasy Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nlpeasy as ne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to running elastic or else start an Open Source stack on your docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No elasticsearch on localhost:9200 found, trying connect to docker container with prefix nlp'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'No docker container with prefix nlp; starting one'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ElasticSearch on <a href='http://localhost:32770'>http://localhost:32770</a> <br> Kibana on <a href='http://localhost:32771'>http://localhost:32771</a>"
      ],
      "text/plain": [
       "ElasticSearch on http://localhost:32770\n",
       "Kibana on http://localhost:32771"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "elk = ne.connect_elastic(dockerPrefix='nlp', elkVersion='7.4.0', mountVolumePrefix=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If it is started on docker it will on the first time pull the images (1.3GB)!\n",
    "BTW, this function is not blocking, i.e. the servers might only be active couple of seconds later.\n",
    "Setting mountVolumePrefix=\"./elastic-data/\" would keep the data of elastic in your\n",
    "filesystems and then the data survives container restarts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data as Pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nips = pd.read_pickle(\"data_raw/nips.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup stages in the NLP pipeline and set textfields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ne.Pipeline(index='nips', textCols=['message','title'], dateCol='year', elk=elk)\n",
    "\n",
    "pipeline += ne.RegexTag(r'\\$([^$]+)\\$', ['message'], 'math')\n",
    "pipeline += ne.VaderSentiment('message', 'sentiment')\n",
    "pipeline += ne.SpacyEnrichment(nlp='en_core_web_md', cols=['message','title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8250/8250 [==============================] - 5:12 38ms/step\n"
     ]
    }
   ],
   "source": [
    "nips_enriched = pipeline.process(nips, writeElastic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Kibana Dashboard of all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nips: adding index-pattern\n",
      "nips: setting default index-pattern\n",
      "nips: adding search\n",
      "nips: adding visualisation for year\n",
      "nips: adding visualisation for math\n",
      "nips: adding visualisation for message_ents\n",
      "nips: adding visualisation for message_subj\n",
      "nips: adding visualisation for message_verb\n",
      "nips: adding visualisation for title_ents\n",
      "nips: adding visualisation for title_subj\n",
      "nips: adding visualisation for title_verb\n",
      "nips: adding visualisation for message\n",
      "nips: adding visualisation for title\n",
      "nips: adding visualisation for sentiment\n",
      "nips: adding dashboard\n",
      "nips: setting time defaults\n"
     ]
    }
   ],
   "source": [
    "pipeline.create_kibana_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Kibana in webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "elk.show_kibana()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shutdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If elastic was started on Docker and you want to shutdown the servers issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ne.docker.stop_elastic_on_docker(\"nlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Warning*: If you didn't use a mountVolumePrefix when you started the servers, all the data in elastic and kibana will be lost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
